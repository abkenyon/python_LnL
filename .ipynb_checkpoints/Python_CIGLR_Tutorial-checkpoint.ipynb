{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d67f65a8",
   "metadata": {},
   "source": [
    "# Welcome to our 1-Hour Python Introduction!\n",
    "\n",
    "This is a jupyter notebook containing a very brief introduction to Python, and the applications it has to CIGLR summer fellows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c4c373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We must import the packages we use for our coding! Python has A LOT of packages\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a7f9d6",
   "metadata": {},
   "source": [
    "# Quick Introduction: Variables, Strings, and Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ad80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a variable\n",
    "\n",
    "# Setting a variable can be integers, floats, or string...you don't have to specify!\n",
    "a = 5\n",
    "b = 10.0\n",
    "c = 'hello'\n",
    "\n",
    "print('int',a)\n",
    "print('float',b)\n",
    "print('string',c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8658034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# math with variables\n",
    "\n",
    "# you can do math between floats and integers...Python will keep the highest precision!\n",
    "\n",
    "test1 = a+b\n",
    "test2 = a+5 # this will stay integer!\n",
    "test3 = a+5.0\n",
    "\n",
    "print(test)\n",
    "print(test2)\n",
    "print(test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8715a1",
   "metadata": {},
   "source": [
    "### Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d1ecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Numpy Python package makes working with arrays incredibly easy. \n",
    "\n",
    "# create random array\n",
    "arr = np.random.rand(10)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5c8dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math with arrays \n",
    "\n",
    "# you can add/multiply a scalar value to an array and it will be applied to all entries\n",
    "arr_add = arr + 1.0\n",
    "print(arr_add)\n",
    "print('')\n",
    "\n",
    "arr_mult = arr * 2.0\n",
    "print(arr_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017783cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also add/multiply two arrays together...but they must be the same shape!\n",
    "\n",
    "#create an array of integers\n",
    "ints = np.arange(0,10)\n",
    "print(ints)\n",
    "print('')\n",
    "\n",
    "# numpy makes it easy to see the \"shape\" of each array\n",
    "print(arr.shape, ints.shape) #<-- each of these arrays have 10 entries\n",
    "print('')\n",
    "\n",
    "# now add them together\n",
    "arr_plus_int = arr + ints\n",
    "print(arr_plus_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9316b7d7",
   "metadata": {},
   "source": [
    "**Activity #1**\n",
    "\n",
    "Find the average between two arrays \"a\" and \"b\", and assign it to the variable \"ab_mean\" (important: do not find the mean of EACH array, instead create a new array that is the average between the two given)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bb8d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.asarray([2,5,8,3,6])\n",
    "b = np.asarray([4,3,2,3,10])\n",
    "\n",
    "# code your solution below\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66ef22c",
   "metadata": {},
   "source": [
    "### Array Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ab5534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy makes it SUPER easy to find the statistics of different arrays\n",
    "\n",
    "# create another random array for example purposes\n",
    "rand = np.random.randint(0,50,size=30).astype(float)\n",
    "print(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ce213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max and min\n",
    "print('max',np.max(rand),'min',np.min(rand))\n",
    "\n",
    "# mean\n",
    "print('mean',np.mean(rand))\n",
    "\n",
    "# standard deviation\n",
    "print('standard deviation',np.std(rand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b0cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UH OH! Our dataset all of a sudden has NaNs! \n",
    "rand[5] = np.nan\n",
    "print(rand)\n",
    "print('')\n",
    "\n",
    "# when you do python math with a nan, there's trouble\n",
    "print('Oh no!' ,1.0 + np.nan)\n",
    "print('')\n",
    "\n",
    "# cue dramatic music\n",
    "print(np.max(rand),np.min(rand),np.mean(rand),np.std(rand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76951ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't worry...there's an easy fix\n",
    "\n",
    "# max and min\n",
    "print('max',np.nanmax(rand),'min',np.nanmin(rand))\n",
    "\n",
    "# mean\n",
    "print('mean',np.nanmean(rand))\n",
    "\n",
    "# standard deviation\n",
    "print('standard deviation',np.nanstd(rand))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fd3a41",
   "metadata": {},
   "source": [
    "Numpy has quite a bit of statistical options. See the link below for additional documentation:\n",
    "\n",
    "https://numpy.org/doc/stable/reference/routines.statistics.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94648dc5",
   "metadata": {},
   "source": [
    "### Indexing Arrays\n",
    "\n",
    "Array \"indexing\" allows us to pull out only a section of an array! But here's the kicker: Python is a 0-based array system! Meaning the first entry is \"the 0th entry\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d005795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the first entry in an array:\n",
    "print(rand[0])\n",
    "\n",
    "# Grab the last entry in an array:\n",
    "print(rand[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da75604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the first four entries in an array:\n",
    "print(rand[:4])\n",
    "\n",
    "# grab the last four entries in an array:\n",
    "print(rand[-4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf63f94f",
   "metadata": {},
   "source": [
    "Another great thing about Numpy arrays is that you can ask for entries in an array that meet a certain condition! This makes it really handy when you have data that isn't QC'd yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05815187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we have an array with 999.0 data in it\n",
    "data = np.asarray([4.,5.,3.2,999.0,6.,5.4,7.8,9.2,999.0,3.1,6.,8.])\n",
    "print(data)\n",
    "print('')\n",
    "\n",
    "# this will really muddy up our statistics\n",
    "print('max',np.max(data),'min',np.min(data),'mean',np.mean(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba983e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best way to take care of these 999 issues is to replace them with NaNs\n",
    "\n",
    "# First, set a condition: we know that this dataset uses 999 as bad data. So our condition will be this:\n",
    "condition = data==999.0\n",
    "print(condition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ca987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we can index the array with that \"condition\"\n",
    "print(data[condition])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453dbc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can assign NEW ENTRIES based on that condition, too! \n",
    "data[condition] = np.nan\n",
    "print(data)\n",
    "print('')\n",
    "\n",
    "# now we can see the true statistics of the data\n",
    "print('max',np.nanmax(data),'min',np.nanmin(data),'mean',np.nanmean(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b645361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about if we DON'T know the bad data code? Just use a reasonable condition\n",
    "data = np.asarray([4.,5.,3.2,999.0,6.,5.4,7.8,9.2,999.0,3.1,6.,8.])\n",
    "condition = data > 500\n",
    "\n",
    "print(data[condition])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f608acd1",
   "metadata": {},
   "source": [
    "**Activity!!!**\n",
    "\n",
    "Using the new array provided (\"array\"), REPLACE every entry that is less than 0 with NaNs (np.nan). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0becdfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.random.randint(-10,20,size=30).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a9ec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code your solution here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1927ce2",
   "metadata": {},
   "source": [
    "# Pandas: A Time-Series Analysis Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f07719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3bc3a6",
   "metadata": {},
   "source": [
    "## A Real Data Example: Opening a CSV into a Pandas Dataframe\n",
    "\n",
    "The CSV file provided contains 2m temperature data and precipitation accumulation data at a 6-hourly resolution from 2019-01-01 to 2021-12-31. The data is from the ERA5 reanalysis, and is taken from the gridpoint closest to CIGLR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b9b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in CSV file of CIGLR temperature and precipitation data from ERA5\n",
    "df = pd.read_csv('era5_ciglr_temp.nc',index_col='time')\n",
    "df.index = pd.to_datetime(df.index) #<--this converts our time index into Pandas Datetime. It's very useful.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d078a211",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# right now, \"t2\" is temperature in Kelvin. Let's convert to Celsius \n",
    "# T(C) = T(K) - 273.15\n",
    "\n",
    "df['t2'] = df['t2']-273.15\n",
    "print(df.head()) # this just prints the first 5 entries\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d375985",
   "metadata": {},
   "source": [
    "**ACTIVITY!!**\n",
    "\n",
    "The precipitation columnn of this data is in units of \"meters\". Please convert to millimeters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9141e1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d4700",
   "metadata": {},
   "source": [
    "## Indexing Pandas Dataframes\n",
    "\n",
    "A dataframe with a Pandas Datetime index (i.e., the first column) is helpful, because we can index our time series based on a desired date, range of dates, year, time, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cc21fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab temp and precip data from one specific day/time\n",
    "date = pd.to_datetime('2019-04-01 00:00:00')\n",
    "print(df.loc[date])\n",
    "print('')\n",
    "\n",
    "# Now grab data from a range of day/times\n",
    "date1 = pd.to_datetime('2019-04-01 00:00:00')\n",
    "date2 = pd.to_datetime('2019-05-01 00:00:00')\n",
    "print(df.loc[date1:date2])\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ad3e16",
   "metadata": {},
   "source": [
    "We rarely are looking for one specific date/time. More often, we want data from one whole year, one whole month, one whole day, etc. Sometimes we are looking for data at the same time every day (i.e., 00Z every day). This is where the **pandas datetime index** comes in handy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9e57f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab data from the year 2020\n",
    "print(df.loc[df.index.year==2020])\n",
    "\n",
    "# How about data from the first of every month?\n",
    "print(df.loc[df.index.day==1])\n",
    "\n",
    "# How about data on 00Z on the first day of every month?\n",
    "print(df.loc[(df.index.day==1)&(df.index.hour==0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e05541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget you can grab only the specific variables! \n",
    "\n",
    "print(df['t2'].head())\n",
    "\n",
    "# The code below gets temperature data from 00Z on the first of every month\n",
    "df['t2'].loc[(df.index.day==1)&(df.index.hour==0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f8c5a3",
   "metadata": {},
   "source": [
    "### Pandas Statistics\n",
    "\n",
    "Much like with numpy arrays, you can find the statistics of a pandas time series using very simple commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1ed784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the max and min temperature during July of 2021.\n",
    "tmax = df['t2'].loc[(df.index.month==7)&(df.index.year==2021)].max()\n",
    "tmin = df['t2'].loc[(df.index.month==7)&(df.index.year==2021)].min()\n",
    "print(tmax,tmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5553effc",
   "metadata": {},
   "source": [
    "**Activity!!!**\n",
    "\n",
    "Find the average difference between temperature at 00Z and temperature at 12Z from 2019-2021 at CIGLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd1f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code your solution here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aa19f7",
   "metadata": {},
   "source": [
    "## Visualizing with Pandas: Plotting a Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939d4166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot our time series of temperature!\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(10,3))\n",
    "df['t2'].plot(ylabel='2 m Temp (C)',title='Temperature at CIGLR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ba8068",
   "metadata": {},
   "source": [
    "Hmm...that's pretty noisy. Let's plot the daiily mean temperature time series instead.\n",
    "\n",
    "The pandas \"resample\" function is INCREDIBLY handy here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e386e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Resample\" our time series at a frequency of 1 Day (or '1D') using \"mean\" as the operator\n",
    "dailymean_df = df['t2'].resample('1D').mean()\n",
    "print(dailymean_df.head())\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(10,3))\n",
    "dailymean_df.plot(ylabel='2 m Temp (C)',title='Daily Mean Temperature at CIGLR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a18fa5",
   "metadata": {},
   "source": [
    "Still too noisy? Lets plot our monthly mean temperatures, and put all three on the same plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812b9072",
   "metadata": {},
   "outputs": [],
   "source": [
    "monmean_df = df['t2'].resample('1M').mean()\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(10,3))\n",
    "\n",
    "df['t2'].plot(ylabel='2 m Temp (C)',color='k',alpha=0.4,\n",
    "              title='Different Frequencies of Temperature at CIGLR')\n",
    "dailymean_df.plot(color='black')\n",
    "monmean_df.plot(color='red',linewidth=2);'\n",
    ";/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c29e1c",
   "metadata": {},
   "source": [
    "Notice...the monthly mean averages are assigned to the first of every month. That's why the red line ends before the rest of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78d266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about precipitation? Histograms are a great way to show precipitation data\n",
    "\n",
    "# get daily precipitation totals!\n",
    "daily_precip = df['precip'].resample('1D').sum()\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(10,4))\n",
    "daily_precip.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dbce1c",
   "metadata": {},
   "source": [
    "The thing about precipitation is that, of COURSE there is going to be a lot of tiny precipitation accumulation amounts (think of how many times we don't get any precip on one day). So let's rearrange the bins (the x-axis) to accomodate this by not including the 0mm days. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bed43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0.1,0.2,0.3,0.4,0.6,0.8,1,1.5,2,3,4,5,10]\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(10,4))\n",
    "daily_precip.plot(kind='hist',bins=bins,edgecolor='k',title='Daily Precipitation (mm)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5625a03",
   "metadata": {},
   "source": [
    "Honestly, it's not the prettiest thing in the world. But it gets the job done. Just for s**** and giggles, let's plot the time series of percipitation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf29b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(10,3))\n",
    "daily_precip.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ea84c8",
   "metadata": {},
   "source": [
    "## More Pandas Statistics\n",
    "\n",
    "Problem: How many days did CIGLR exceed the 99th percentile of precipitation for the location? By how much?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f5a43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, find the upper 99th percentile, or \"quantile\", value for precipitation\n",
    "ninenine_perc = daily_precip.quantile(0.99)\n",
    "print(ninenine_perc)\n",
    "\n",
    "# Create a dataframe containing only days that exceed that amount\n",
    "df_upper = daily_precip[daily_precip>=ninenine_perc]\n",
    "\n",
    "# How many days exceed the 99th percentile of precip?\n",
    "print(len(df_upper),'days')\n",
    "\n",
    "# By how much did each day exceed the upper percentile?\n",
    "print(df_upper-ninenine_perc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9d416e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
